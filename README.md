# 멀티모달 AI 기반 포켓몬 이미지 및 캡션 분석 모델


![Python](https://img.shields.io/badge/Python-3.1%2B-blue.svg)
![TensorFlow](https://img.shields.io/badge/TensorFlow-2.17-orange.svg)
![Keras](https://img.shields.io/badge/Keras-blueviolet.svg)

---

## 1. 📖 프로젝트 소개 (Project Introduction)

### 배경 및 문제 정의
기존의 이미지 분류는 주로 이미지 자체의 정보만을 사용하는 경우가 많습니다. 하지만 실제 환경에서는 이미지와 텍스트 설명이 함께 존재하는 경우가 많으며, 이러한 데이터를 동시에 이해하고 처리하는 멀티모달(Multimodal) AI가 주목받고 있습니다 본 프로젝트는 이미지와 캡션 데이터를 함께 학습하는 모델의 필요성에서 시작되었습니다.

### 프로젝트 목표
포켓몬 이미지와 그에 대한 설명 캡션을 함께 분석하는 멀티모달 AI 모델을 구축하는 것을 목표로 합니다. 이미지 특징 추출에는 사전 학습된 `EfficientNetB0` 모델을, 텍스트 처리를 위해서는 `LSTM` 신경망을 활용하여 두 정보를 효과적으로 결합합니다.

### 기대 효과
- 이미지와 텍스트 사이의 관계 이해도를 높일 수 있습니다.
- 자동 이미지 태깅, 콘텐츠 검색 시스템의 정확도 향상 등에 활용될 수 있습니다.
- 전자상거래, SNS 등 다양한 서비스에서 콘텐츠 분류 및 추천 시스템을 고도화하는 데 기여할 수 있습니다.

---

## 2. 🛠️ 기술 스택 및 학습 환경 (Tech Stack & Environment)

- **Framework**: TensorFlow 2.17, Keras
- **Key Libraries**: Pandas, Scikit-learn, Matplotlib, Numpy, Pickle
- **손실 함수 (Loss Function)**: `binary_crossentropy` (이진 분류 문제에 적합)
- **최적화 알고리즘 (Optimizer)**: `Adam` (적응적 학습률과 모멘텀 결합)
- **학습률 (Learning Rate)**: `1e-4` (0.0001) 
- **배치 크기 (Batch Size)**: 32 
- **에포크 (Epochs)**: 최대 30회, `EarlyStopping` 적용 

---

## 3. 💾 데이터 준비 (Data Preparation)

### 데이터셋
- 포켓몬 이미지와 해당 이미지에 대한 설명 텍스트(캡션)를 사용합니다.
- 전처리 후 총 1,025개의 유효한 이미지-캡션 쌍으로 데이터셋을 구성했습니다.

### 전처리 (Preprocessing)
- **이미지**: 모든 이미지의 크기를 `224x224`로 통일하고 [cite: 48][cite_start], 과적합 방지를 위해 좌우 반전, 회전, 줌 등 데이터 증강을 적용했습니다.
- **텍스트**: `Tokenizer`를 사용해 캡션을 정수 시퀀스로 변환하고, `pad_sequences`를 통해 모든 시퀀스의 길이를 통일했습니다.

---

## 4. 🧠 모델 아키텍처 (Model Architecture)

본 모델은 이미지와 텍스트를 각각 처리하는 두 개의 브랜치(Branch)가 특징을 추출한 뒤, 이를 결합하여 최종 예측을 수행하는 구조입니다.
![image](https://github.com/user-attachments/assets/deca7958-58d9-4619-9d1b-c1c03001e1b8)

---

## 5. 📈 학습 결과 (Results & Evaluation)

- **손실 (Loss)**: 훈련 손실은 점진적으로 감소하여 약 0.4에서 안정화되었고, 검증 손실은 0.25까지 감소하여 학습이 안정적으로 진행되었음을 확인했습니다.
- **정확도 (Accuracy)**: 훈련 정확도는 약 83%까지 상승했으며, 검증 정확도는 최종적으로 100%에 근접하여 모델이 검증 데이터를 매우 효과적으로 분류함을 보였습니다.
- **테스트 결과**: 실제 매칭되는 이미지-캡션 쌍을 입력했을 때, 약 87.5%의 확률로 '긍정' 클래스를 예측하여 멀티모달 입력의 연관성을 성공적으로 판단했습니다.

---

## 6. 🏁 결론 및 향후 계획 (Conclusion & Future Work)

### 프로젝트 요약 및 의의
이미지와 텍스트를 함께 처리하는 멀티모달 AI 모델을 성공적으로 구현했으며, 이를 통해 복합 정보 처리의 가능성을 확인하고 이미지 검색, 자동 태깅 등 다양한 응용의 기반을 마련했습니다.

### 한계점
- **데이터 부족**: 1,025개의 데이터는 모델의 일반화 성능을 확보하기에 제한적입니다.
- **일반화 성능**: 새로운 데이터에 대한 성능 개선이 필요합니다.
- **라벨 불균형**: 데이터의 클래스(라벨) 간 불균형 문제가 있을 수 있습니다.
### 향후 계획
- 더 다양한 데이터를 추가하고 모델의 분류 기준을 재점검하여 신뢰도를 높일 계획입니다.
- 실제 프로젝트에 적용하며 피드백을 반영하고 모델을 고도화할 예정입니다.

---


                    
